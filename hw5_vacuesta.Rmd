---
title: "hw5_vacuesta"
author: "vincent acuesta"
date: "4/16/2019"
output: html_document
---
problem_1a
```{r problem_1a}

data<-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep=",")

colnames(data)<-c("Origin","Alcohol","MalicAcid","Ash","AlcalinityOfAsh","Magnesium","TotalPhenols","Flavanoids","NonflavanoidPhenols","Proanthocyanins","ColorIntensity","Hue","OD280/OD315OfDilutedWines","Proline")

#labeling Origin
data$Origin[data$Origin==1]<-1
data$Origin[data$Origin==2]<-0
data$Origin[data$Origin==3]<-0
x<-data[sample(1:nrow(data)),]

#logistic regression model
model2 <- glm(Origin ~ .,family = binomial(logit), data=x)
summary(model2)

```
This says that the model is not the best because all the p-values are 1 which tells us that no variable would be a good addition to the model. If you add any of thse variables you will not get a more accurate prediction. 




Problem_1b
```{r problem_1b}
data<-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep=",")

colnames(data)<-c("Origin","Alcohol","MalicAcid","Ash","AlcalinityOfAsh","Magnesium","TotalPhenols","Flavanoids","NonflavanoidPhenols","Proanthocyanins","ColorIntensity","Hue","OD280/OD315OfDilutedWines","Proline")

#labeling Origin
data$Origin[data$Origin==1]<-1
data$Origin[data$Origin==2]<-0
data$Origin[data$Origin==3]<-0
x<-data[sample(1:nrow(data)),]

library(MASS)
stepAIC(model2, direction="both")

summary(model2)

```
After all the runs there are 5 variables that are left in the remaining model.
The logistic function that is made from this model is ln(p/1-p)= (2.77e+01)+(5.722e+01)+(-6.067e+00)+(1.944e+01)+(8.028e-02). We did the AIC process to pick a better model. The numbers that are represented in the best model equation were the estimates seen in the summary plot. 







problem_2a
```{r Problem_2a}
#install.packages("caret")
library(caret)

data<-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep=",")

colnames(data)<-c("Origin","Alcohol","MalicAcid","Ash","AlcalinityOfAsh","Magnesium","TotalPhenols","Flavanoids","NonflavanoidPhenols","Proanthocyanins","ColorIntensity","Hue","OD280/OD315OfDilutedWines","Proline")

#labeling Origin
data$Origin[data$Origin==1]<-1
data$Origin[data$Origin==2]<-0
data$Origin[data$Origin==3]<-0
x<-data[sample(1:nrow(data)),]

k<-10
acc <- NULL

set.seed(123)
for(i in 1:k){
Train <- createDataPartition(data$Origin, p=0.75, list=FALSE)
training <- data[ Train, ]
testing <- data[ -Train, ]

bestModel<-glm(formula = Origin ~ Alcohol + Ash + AlcalinityOfAsh + `OD280/OD315OfDilutedWines` + 
    Proline, family = binomial(logit), data = training)

pred<-predict(bestModel, newdata=testing,type="response")

results <- ifelse(pred > 0.5,1,0)
answers <- testing$Origin
misClasificError <- mean(answers != results)
acc[i]=1-misClasificError
}
mean(acc)

# Histogram of accuracy
hist(acc,xlab='Accuracy',ylab='Freq',
col='cyan',border='blue',density=30)

# Boxplot of accuracy
boxplot(acc,col='cyan',border='blue',horizontal=T,xlab='Accuracy',
main='Accuracy CV')

```
problem_2b
```{r problem_2b}


data<-read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", sep=",")

colnames(data)<-c("Origin","Alcohol","MalicAcid","Ash","AlcalinityOfAsh","Magnesium","TotalPhenols","Flavanoids","NonflavanoidPhenols","Proanthocyanins","ColorIntensity","Hue","OD280/OD315OfDilutedWines","Proline")

#labeling Origin
data$Origin[data$Origin==1]<-1
data$Origin[data$Origin==2]<-0
data$Origin[data$Origin==3]<-0
x<-data[sample(1:nrow(data)),]

#LEAVE ONE OUT CROSS VALIDATION

acc1 <- NULL
for(i in 1:nrow(x))
{
    # Train-test splitting
    # 177 samples -> fitting
    # 1 sample -> testing
    train <- x[-i,]
    test <- x[i,]
    
    # Fitting
bestModel<-glm(formula = Origin ~ Alcohol + Ash + AlcalinityOfAsh + `OD280/OD315OfDilutedWines` + 
    Proline, family = binomial(logit), data = training)
    
    # Predict results
    pred1 <- predict(bestModel,newdata=test,type="response")
    
    # If prob > 0.5 then 1, else 0
    results1 <- ifelse(pred1 > 0.5,1,0)
    
    # Actual answers
    answers1 <- test$Origin
    
    # Calculate accuracy
    misClasificError1 <- mean(answers1 != results1)
    
    # Collecting results
    acc1[i] <- 1-misClasificError1
}

# Average accuracy of the model
mean(acc1)







```
The data is 1. The purpose of the leave-one out cross validation was to make sure that K is equal to N which is basically the number of data points in the set. All the data is trained and then the model is used for that one point. This basically shows that after doing the LOO cross validation this is the same as the best model that was calculated from 1b, this shows that the there is 100 percent accuracy when training the models. 




problem_3a
```{r problem_3a}

library(MASS)
data("mtcars")
data<- mtcars

x<-data$gear
y<-data$carb
  
shapiro.test(x)
shapiro.test(y)


#3a
cor.test(x,y, method = 'spearman')









```
That data is not normal accourding to shapiro. With that being said after figuring that the data is ordinal because of the variables taht were being used here. The correlation test proved that the p value was 0.5312 which means that we fail to reject that there is anything signifcant between the number of gears and the number of carbs. 






problem_3b
```{r problem_3b}

library(MASS)
data("mtcars")
data<- mtcars

x1<-data$mpg
y1<-data$hp
  
shapiro.test(x)
shapiro.test(y)


#3b
cor.test(x1,y1, method = 'kendall')






```
With the correlation done using a Kendall method assuming that these are not ordinal. Logically they are not ordinal because thinking about it further you are unable to order power. Horse power is something that can be measured but you can't order it. With the p value being as low as 4.332e-09 that means that we reject the null hypothesis which means that indicates that there is a correlation between the number of mpg's and the number of hp's






problem_3c
```{r problem_3c}


library(MASS)
data("mtcars")
data<- mtcars

x2<-data$mpg
y2<-data$gear
  
shapiro.test(x)
shapiro.test(y)


#3c
cor.test(x2,y2, method = 'spearman')




```
Considering that one of the variables is ordinal which is gears taht means that we go straight into spearmans which goes into assuming that the variables are ordinal. So with the p value being 0.001329 which is less than 0.04. We reject the null hypothesis which means that there is a correlation between the mpg's and the number of gears.

